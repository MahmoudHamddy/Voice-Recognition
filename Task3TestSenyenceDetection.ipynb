{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc9c971e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import sklearn\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ef3bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names = []\n",
    "# Letter_names = [\"M\", \"S\", \"B\", \"Y\"]\n",
    "# for letter in Letter_names:\n",
    "#     for index in range(15):\n",
    "#         names.append({'file':\"{0}_open_({1}).wav\".format(letter, index), 'label':\"{0}\".format(letter)})\n",
    "# file_name = pd.DataFrame(names)\n",
    "# print(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e4e3518c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Paths  Labels\n",
      "0    AuphonicRecording_Sherif Close The Window (1).wav       0\n",
      "1    AuphonicRecording_Sherif Close The Window (2).wav       0\n",
      "2    AuphonicRecording_Sherif Close The Window (3).wav       0\n",
      "3    AuphonicRecording_Sherif Close The Window (4).wav       0\n",
      "4    AuphonicRecording_Sherif Close The Window (5).wav       0\n",
      "..                                                 ...     ...\n",
      "259                                    y_close_(5).wav       0\n",
      "260                                    y_close_(6).wav       0\n",
      "261                                    y_close_(7).wav       0\n",
      "262                                    y_close_(8).wav       0\n",
      "263                                    y_close_(9).wav       0\n",
      "\n",
      "[264 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "Names = os.listdir(\"AllRecords//close\")\n",
    "Close_Names_df = pd.DataFrame(Names, columns={'Paths'})\n",
    "Close_Names_df.insert(1, \"Labels\", len(Names) *[0])\n",
    "print(Close_Names_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6fa2944c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Paths  Labels\n",
      "0    AuphonicRecording_Sherief Open The Door (1).wav       1\n",
      "1    AuphonicRecording_Sherief Open The Door (2).wav       1\n",
      "2    AuphonicRecording_Sherief Open The Door (3).wav       1\n",
      "3    AuphonicRecording_Sherief Open The Door (4).wav       1\n",
      "4    AuphonicRecording_Sherief Open The Door (5).wav       1\n",
      "..                                               ...     ...\n",
      "279                    yassmen open the door (5).wav       1\n",
      "280                    yassmen open the door (6).wav       1\n",
      "281                    yassmen open the door (7).wav       1\n",
      "282                    yassmen open the door (8).wav       1\n",
      "283                    yassmen open the door (9).wav       1\n",
      "\n",
      "[284 rows x 2 columns]\n",
      "                                               Paths  Labels\n",
      "0    AuphonicRecording_Sherief Open The Door (1).wav       1\n",
      "1    AuphonicRecording_Sherief Open The Door (2).wav       1\n",
      "2    AuphonicRecording_Sherief Open The Door (3).wav       1\n",
      "3    AuphonicRecording_Sherief Open The Door (4).wav       1\n",
      "4    AuphonicRecording_Sherief Open The Door (5).wav       1\n",
      "..                                               ...     ...\n",
      "543                                  y_close_(5).wav       0\n",
      "544                                  y_close_(6).wav       0\n",
      "545                                  y_close_(7).wav       0\n",
      "546                                  y_close_(8).wav       0\n",
      "547                                  y_close_(9).wav       0\n",
      "\n",
      "[548 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmo\\AppData\\Local\\Temp\\ipykernel_25504\\4113759299.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  all = Open_Names_df.append(Close_Names_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#Getting Team information\n",
    "Names2 = os.listdir(\"AllRecords//open\")\n",
    "Open_Names_df = pd.DataFrame(Names2, columns={'Paths'})\n",
    "Open_Names_df.insert(1, \"Labels\", len(Names2) *[1])\n",
    "print(Open_Names_df)\n",
    "all = Open_Names_df.append(Close_Names_df, ignore_index=True)\n",
    "print(all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "601884ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Extract_features(paths, whichone, dowhat = ''):\n",
    "    path = os.path.join(os.path.abspath('AllRecords/{0}').format(whichone)+ ('\\\\') +str(paths['Paths']))\n",
    "    # X, sample_rate = librosa.load(path, res_type = \"kaiser_fast\")\n",
    "    # X, index    = librosa.effects.trim(X)\n",
    "    # chroma_stft = librosa.feature.chroma_stft(y=X, sr=sample_rate)\n",
    "    # rmse = librosa.feature.rms(y=X)\n",
    "    # spec_cent = librosa.feature.spectral_centroid(y=X, sr=sample_rate) \n",
    "    # spec_bw = librosa.feature.spectral_bandwidth(y=X, sr=sample_rate)\n",
    "    # rolloff = librosa.feature.spectral_rolloff(y=X, sr=sample_rate)\n",
    "    # zcr = librosa.feature.zero_crossing_rate(y=X)\n",
    "    # mfcc = librosa.feature.mfcc(y=X, sr=sample_rate,n_mfcc=40) \n",
    "    # to_append   = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "    # for e in mfcc:\n",
    "    #     to_append += f' {np.mean(e)}'\n",
    "    # features=[]\n",
    "    # features.append(to_append.split())\n",
    "    # print(len(features[0]))\n",
    "\n",
    "    # for counter in range(0,len(features[0])):\n",
    "    #     features[0][counter]=float(features[0][counter])\n",
    "    # # return [chroma_stft, rmse, spec_cent, spec_bw, rolloff,zcr,mfcc]\n",
    "    # # return [chroma_stft, rmse, spec_cent, spec_bw, rolloff,zcr,mfcc]\n",
    "    # return features\n",
    "    # features=[]\n",
    "    # reading records\n",
    "    y, sr = librosa.load(path,res_type='kaiser_fast')\n",
    "    # remove leading and trailing silence\n",
    "    y, index    = librosa.effects.trim(y)\n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    rmse        = librosa.feature.rms(y=y)\n",
    "    spec_cent   = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw     = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff     = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr         = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc        = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    # to_append   = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "    # for e in mfcc:\n",
    "    #     to_append += f' {np.mean(e)}'\n",
    "    \n",
    "    # features.append(to_append.split())\n",
    "    # # print(len(features[0]))\n",
    "    \n",
    "    # for counter in range(0,len(features[0])):\n",
    "    #     features[0][counter]=float(features[0][counter])\n",
    "\n",
    "    # return features\n",
    "    return [chroma_stft, rmse, spec_cent, spec_bw, rolloff,zcr,mfcc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49a73412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [[[0.10397341, 0.1377187, 0.0813543, 0.0807806...\n",
      "1      [[[0.94728476, 0.6589324, 0.91914415, 1.0, 0.5...\n",
      "2      [[[0.2787472, 0.5081707, 0.41435555, 0.328101,...\n",
      "3      [[[1.0, 1.0, 0.99109715, 0.93272287, 0.4674527...\n",
      "4      [[[0.43665874, 0.4805539, 0.43445337, 0.512618...\n",
      "                             ...                        \n",
      "543    [[[1.0, 0.82806844, 0.95903087, 1.0, 0.924533,...\n",
      "544    [[[0.53762746, 0.7825138, 0.8607997, 1.0, 0.58...\n",
      "545    [[[0.87527734, 0.83723205, 0.7751678, 0.787379...\n",
      "546    [[[0.79039603, 0.7560549, 0.66985595, 1.0, 0.9...\n",
      "547    [[[0.44455808, 0.62409323, 0.6815331, 0.826901...\n",
      "Length: 548, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mahmo\\AppData\\Local\\Temp\\ipykernel_25504\\3386549790.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  dd = np.array(DataSet[0])\n"
     ]
    }
   ],
   "source": [
    "mfccs = []\n",
    "mel = []\n",
    "tonnetz = []\n",
    "chroma = []\n",
    "contrast = []\n",
    "label_enter = []\n",
    "DataSet = pd.DataFrame()\n",
    "DataSet = all.apply(Extract_features, whichone=\"AllTeams\", axis=1)\n",
    "dd = np.array(DataSet[0])\n",
    "print(DataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2945ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_append(features):\n",
    "    feature = []\n",
    "    # features[0][5] = [features[0][5]]\n",
    "    for i in range(len(features)):\n",
    "        # print(features[0][1],'1')\n",
    "        # print(features[0][2], '2')\n",
    "        # print(features[0][3], '3')\n",
    "        # print(features[0][4], '4')\n",
    "        # print(features[0][5], '5')\n",
    "        # feature.append(np.concatenate((features[i][0], features[i][1], features[i][2]\n",
    "        # , features[i][3],features[i][4],features[i][5], features[i][6]), axis=0))\n",
    "        to_append   = f'{np.mean(features[i][0])} {np.mean(features[i][1])} {np.mean(features[i][2])} {np.mean(features[i][3])} {np.mean(features[i][4])} {np.mean(features[i][5])}'\n",
    "        for e in features[i][6]:\n",
    "            to_append += f' {np.mean(e)}'\n",
    "        # print(to_append.split())\n",
    "        feature.append(to_append.split())\n",
    "        if(i==0):\n",
    "            print(feature)\n",
    "\n",
    "    # print(\"These are: \",features)\n",
    "    # print(\"The length\",len(features[0]))\n",
    "    # print(feature)\n",
    "    for j in range(len(features)):\n",
    "        for index in range(0,len(feature[j])):\n",
    "            # print(i, index)\n",
    "            # print(feature[i][index])\n",
    "            feature[j][index]=float(feature[j][index])\n",
    "\n",
    "    return feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9dae046b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0.3431890904903412', '0.07531614601612091', '1900.5250272933993', '2081.5942793422764', '3765.94189453125', '0.0849560546875', '-331.0139465332031', '107.94735717773438', '24.277204513549805', '11.558176040649414', '-19.487794876098633', '4.600085258483887', '-16.40422821044922', '-10.175797462463379', '-11.678380966186523', '-9.083390235900879', '-13.660134315490723', '-3.213951349258423', '-19.12630844116211', '-3.7342135906219482', '-0.3473721444606781', '-1.137442708015442', '-11.253403663635254', '0.32225072383880615', '1.6086572408676147', '-5.872960090637207']]\n",
      "2nd [0.3431890904903412, 0.07531614601612091, 1900.5250272933993, 2081.5942793422764, 3765.94189453125, 0.0849560546875, -331.0139465332031, 107.94735717773438, 24.277204513549805, 11.558176040649414, -19.487794876098633, 4.600085258483887, -16.40422821044922, -10.175797462463379, -11.678380966186523, -9.083390235900879, -13.660134315490723, -3.213951349258423, -19.12630844116211, -3.7342135906219482, -0.3473721444606781, -1.137442708015442, -11.253403663635254, 0.32225072383880615, 1.6086572408676147, -5.872960090637207]\n"
     ]
    }
   ],
   "source": [
    "# print('1st data',DataSet[2])\n",
    "# print('2nd data',DataSet[0][1])\n",
    "# print('3rd data',DataSet[0])\n",
    "# print('4th data',DataSet[0][3])\n",
    "# print('5th data',DataSet[0][4])\n",
    "# print('6th data',DataSet[0][5])\n",
    "# print('7th data',DataSet[0][6])\n",
    "# for i in range(len(DataSet)):\n",
    "#     DataSet[i][0]=DataSet[i][0][0]\n",
    "# print(len(DataSet[0]))\n",
    "x = features_append(DataSet)\n",
    "# x = DataSet\n",
    "# df = pd.DataFrame(x)\n",
    "# for i in range(len(x)):\n",
    "#     x[i] = x[i][0]\n",
    "print('2nd',x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4c6a6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3077155649662018\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, all['Labels'], test_size=0.2, random_state=0)\n",
    "# X_train = [X_train]\n",
    "print(X_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a5802e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = RandomForestClassifier(random_state=0, n_estimators=40)\n",
    "clf = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "clf.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ce35fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7e06cebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "49bd77c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85     1\n",
       "438    0\n",
       "96     1\n",
       "172    1\n",
       "134    1\n",
       "      ..\n",
       "379    0\n",
       "185    1\n",
       "76     1\n",
       "395    0\n",
       "313    0\n",
       "Name: Labels, Length: 110, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e16a016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6727272727272727\n"
     ]
    }
   ],
   "source": [
    "a = accuracy_score(y_pred, y_test)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59207127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(x[:12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04479da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     1\n",
       "5     1\n",
       "6     1\n",
       "7     1\n",
       "8     1\n",
       "9     1\n",
       "10    1\n",
       "11    1\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all['Labels'][:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43638590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "[['0.47074562311172485', '0.006534410174936056', '1508.3056738658613', '1845.219788005738', '3159.6502488659276', '0.054908014112903226', '-533.5375366210938', '119.29576873779297', '-1.6009817123413086', '32.47652816772461', '-7.533818244934082', '17.795495986938477', '14.32162857055664', '1.421666145324707', '-15.793218612670898', '-1.4759856462478638', '-1.8549346923828125', '3.713296890258789', '5.0833964347839355', '0.881470263004303', '8.37099838256836', '16.475154876708984', '5.7274861335754395', '0.6608526110649109', '0.9324504137039185', '3.5562145709991455']]\n",
      "Length 26\n"
     ]
    }
   ],
   "source": [
    "newTest = os.listdir(\"AllRecords/Test/\")\n",
    "Test = pd.DataFrame(newTest, columns={\"Paths\"})\n",
    "l=os.path.join(os.path.abspath('AllRecords/Test/{0}')).format(Test['Paths'][9])\n",
    "y,sr = librosa.load(l, res_type='kaiser_fast')\n",
    "\n",
    "chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "rmse        = librosa.feature.rms(y=y)\n",
    "spec_cent   = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "spec_bw     = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "rolloff     = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "zcr         = librosa.feature.zero_crossing_rate(y)\n",
    "mfcc        = librosa.feature.mfcc(y=y, sr=sr)\n",
    "to_append   = f'{np.mean(chroma_stft)} {np.mean(rmse)} {np.mean(spec_cent)} {np.mean(spec_bw)} {np.mean(rolloff)} {np.mean(zcr)}'\n",
    "for e in mfcc:\n",
    "    to_append += f' {np.mean(e)}'\n",
    "features=[]\n",
    "features.append(to_append.split())\n",
    "print(len(features[0]))\n",
    "\n",
    "for counter in range(0,len(features[0])):\n",
    "    features[0][counter]=float(features[0][counter])\n",
    "\n",
    "get_feat = Test.apply(Extract_features, whichone='Test', axis=1)\n",
    "combine = features_append(get_feat)\n",
    "# print(combine[0])\n",
    "print(\"Length\", len(combine[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "efda6071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7f99dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(clf, open(\"Sentence-model2.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6aa21aa2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mahmo\\OneDrive\\Documents\\GitHub\\DSP_Task3_TeamNo\\Task3TestSenyenceDetection.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mahmo/OneDrive/Documents/GitHub/DSP_Task3_TeamNo/Task3TestSenyenceDetection.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m clf \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mDecisionTreeClassifier(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mahmo/OneDrive/Documents/GitHub/DSP_Task3_TeamNo/Task3TestSenyenceDetection.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m iris \u001b[39m=\u001b[39m load_iris()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mahmo/OneDrive/Documents/GitHub/DSP_Task3_TeamNo/Task3TestSenyenceDetection.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mfit(iris\u001b[39m.\u001b[39mdata, iris\u001b[39m.\u001b[39mtarget)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier(random_state=42)\n",
    "iris = load_iris()\n",
    "\n",
    "clf = clf.fit(iris.data, iris.target)\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,\n",
    "                                feature_names=iris.feature_names,\n",
    "                                class_names=iris.target_names,\n",
    "                                filled=True, rounded=True,\n",
    "                                special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "\n",
    "# empty all nodes, i.e.set color to white and number of samples to zero\n",
    "for node in graph.get_node_list():\n",
    "    if node.get_attributes().get('label') is None:\n",
    "        continue\n",
    "    if 'samples = ' in node.get_attributes()['label']:\n",
    "        labels = node.get_attributes()['label'].split('<br/>')\n",
    "        for i, label in enumerate(labels):\n",
    "            if label.startswith('samples = '):\n",
    "                labels[i] = 'samples = 0'\n",
    "        node.set('label', '<br/>'.join(labels))\n",
    "        node.set_fillcolor('white')\n",
    "\n",
    "samples = iris.data[129:130]\n",
    "decision_paths = clf.decision_path(samples)\n",
    "\n",
    "for decision_path in decision_paths:\n",
    "    for n, node_value in enumerate(decision_path.toarray()[0]):\n",
    "        if node_value == 0:\n",
    "            continue\n",
    "        node = graph.get_node(str(n))[0]            \n",
    "        node.set_fillcolor('green')\n",
    "        labels = node.get_attributes()['label'].split('<br/>')\n",
    "        for i, label in enumerate(labels):\n",
    "            if label.startswith('samples = '):\n",
    "                labels[i] = 'samples = {}'.format(int(label.split('=')[1]) + 1)\n",
    "\n",
    "        node.set('label', '<br/>'.join(labels))\n",
    "\n",
    "filename = 'tree.png'\n",
    "graph.write_png(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
